{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMorvhNlayQXRo3mTSKBMNB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naterattner/data71200/blob/master/project_3/data71200_summer24_project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python notebook for project 3: https://bbhosted.cuny.edu/ultra/courses/_2383576_1/cl/outline\n",
        "\n",
        "The goal for this assignment is two apply different types of unsupervised learning techniques on the dataset created in Project 1.\n",
        "\n",
        "I'll be using this dataset containing estimations of obesity levels based on eating habits and physical condition: https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition"
      ],
      "metadata": {
        "id": "sgD0FXp6Mi0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.plotting import scatter_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install -U scikit-learn==1.4\n",
        "!pip install mglearn\n",
        "import mglearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAGpKBYMMzf2",
        "outputId": "8899a9a2-1019-4b43-abdc-48091b5ba4da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==1.4\n",
            "  Downloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4) (3.5.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.4.0\n",
            "Collecting mglearn\n",
            "  Downloading mglearn-0.2.0-py2.py3-none-any.whl (581 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.4/581.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mglearn) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mglearn) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from mglearn) (1.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mglearn) (2.0.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from mglearn) (9.4.0)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from mglearn) (0.12.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from mglearn) (2.31.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from mglearn) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mglearn) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mglearn) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mglearn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mglearn) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mglearn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mglearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mglearn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mglearn) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->mglearn) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->mglearn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mglearn) (1.16.0)\n",
            "Installing collected packages: mglearn\n",
            "Successfully installed mglearn-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load data, including testing/training split from Project 1\n",
        "\n",
        "We will perform four steps in this section:\n",
        "- Load the dataset from UCI\n",
        "- Performing one-hot encoding on categorical features\n",
        "- Split the data into a testing and training set\n",
        "- Scale the data using StandardScaler"
      ],
      "metadata": {
        "id": "XDBYuovBM7u-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data from UCI"
      ],
      "metadata": {
        "id": "0dY6wbZ0NBtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition = fetch_ucirepo(id=544)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "features = estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.data.features\n",
        "targets = estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.data.targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1tfiHQIM47u",
        "outputId": "87dcb294-49b5-4af0-cb5e-322ee97a8e91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform one-hot encoding\n",
        "Because the dataset contains categorical variables, we will first perform one-hot encoding. This is done on a Dataframe containing all data to ensure categorical values are represented in the same way in both the testing and training sets.\n",
        "\n",
        "Once one-hot encoding is done, we split the data into testing and training sets."
      ],
      "metadata": {
        "id": "11LWPV7ONs7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the categorical features\n",
        "data_dummies = pd.get_dummies(features, dtype=int)\n",
        "\n",
        "# Encode the target variable using LabelEncoder\n",
        "# This encodes labels that were in the target data with values\n",
        "# from 0 through n_classes-1, so 0 through 6 in this case\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 'NObeyesdad' is the target column\n",
        "label_encoder = LabelEncoder()\n",
        "targets_encoded = label_encoder.fit_transform(targets['NObeyesdad'])"
      ],
      "metadata": {
        "id": "8OuEoAmuOs64"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split into testing and training sets"
      ],
      "metadata": {
        "id": "6lKk1j5HQAFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_dummies\n",
        "y = targets_encoded\n",
        "print(\"X.shape: {} y.shape: {}\".format(X.shape, y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7LYao0aQB2y",
        "outputId": "6d276db7-f046-4d61-a641-4501b577fbff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape: (2111, 31) y.shape: (2111,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# From project 1 we know the data is fairly evenly distributed,\n",
        "# but we can still use stratified sampling on the target to avoid sampling bias\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, stratify=y, random_state=42,test_size=0.2)"
      ],
      "metadata": {
        "id": "NinY0oe2QGhO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that the strafied sampling worked -- the distribution of targets should be the same in each dataset\n",
        "\n",
        "def getArrayValueCounts(array):\n",
        "  unique, counts = np.unique(array, return_counts=True)\n",
        "  total_count = counts.sum()\n",
        "  shares = counts / total_count\n",
        "\n",
        "  print(\"Unique values:\", unique)\n",
        "  print(\"Counts:\", counts)\n",
        "  print(\"Shares:\", shares)\n",
        "\n",
        "print('Test')\n",
        "getArrayValueCounts(y_test)\n",
        "print(\"\")\n",
        "print('Train')\n",
        "getArrayValueCounts(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgvBN1YyQKDz",
        "outputId": "0df9907b-a975-4b5b-f039-046d3a404cff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test\n",
            "Unique values: [0 1 2 3 4 5 6]\n",
            "Counts: [54 58 70 60 65 58 58]\n",
            "Shares: [0.12765957 0.13711584 0.16548463 0.14184397 0.1536643  0.13711584\n",
            " 0.13711584]\n",
            "\n",
            "Train\n",
            "Unique values: [0 1 2 3 4 5 6]\n",
            "Counts: [218 229 281 237 259 232 232]\n",
            "Shares: [0.12914692 0.13566351 0.16646919 0.14040284 0.15343602 0.13744076\n",
            " 0.13744076]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scale the data"
      ],
      "metadata": {
        "id": "hpkwmoXrS4gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "e_a-SspjS4Hh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: PCA for feature selection"
      ],
      "metadata": {
        "id": "-9Lnll7AThzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6HZkKhQpTlNy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}